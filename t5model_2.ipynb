{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lsemi\\anaconda3\\envs\\KIBU3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "All model checkpoint layers were used when initializing TFT5Model.\n",
      "\n",
      "All the layers of TFT5Model were initialized from the model checkpoint at google-t5/t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5Model for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFViTModel.\n",
      "\n",
      "All the layers of TFViTModel were initialized from the model checkpoint at google/vit-base-patch16-224-in21k.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from transformers import T5Tokenizer, TFT5Model\n",
    "from transformers import ViTImageProcessor, TFViTModel\n",
    "\n",
    "pretrained_t5_path = 'google-t5/t5-small'\n",
    "pretrained_vit_path = 'google/vit-base-patch16-224-in21k'\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(pretrained_t5_path)\n",
    "t5 = TFT5Model.from_pretrained(pretrained_t5_path)\n",
    "t5_encoder = t5.encoder\n",
    "\n",
    "vit = TFViTModel.from_pretrained(pretrained_vit_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, TFT5Model, TFViTModel\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "import tensorflow as tf\n",
    "\n",
    "def VQAModel(t5,vit):\n",
    "    visual_embedding_shape = (197, 768)\n",
    "    text_embedding_shape = (15, 512)\n",
    "    \n",
    "    visual_embedding = Input(visual_embedding_shape, name='visual_embedding')\n",
    "    text_embedding = Input(text_embedding_shape, name='text_embedding')\n",
    "\n",
    "    # 視覚埋め込みをテキスト埋め込みの次元に合わせて変換\n",
    "    x_v = layers.Dense(\n",
    "        units=text_embedding_shape[1], \n",
    "        activation='relu', \n",
    "        use_bias=True,\n",
    "    )(visual_embedding)\n",
    "    \n",
    "    # 注意機構を適用して視覚とテキストの埋め込みを組み合わせる\n",
    "    attention_output = layers.Attention()([x_v, text_embedding])\n",
    "    \n",
    "    # 出力を結合\n",
    "    x = layers.Concatenate(axis=1)([attention_output, text_embedding])\n",
    "\n",
    "    # 結合された埋め込みをT5デコーダに入力するためのエンコードを行う\n",
    "    decoder_input_ids = layers.Input(shape=(None,), dtype=tf.int32, name='decoder_input_ids')\n",
    "    t5_output = t5.decoder(input_ids=decoder_input_ids, encoder_hidden_states=x).last_hidden_state\n",
    "\n",
    "    return Model(inputs=[visual_embedding, text_embedding, decoder_input_ids], outputs=t5_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1.84944905e-02  9.05140862e-02 -1.20279394e-01 ...  6.31373525e-02\n",
      "   -3.64452512e-06 -1.87197119e-01]\n",
      "  [-1.64691042e-02  4.84788939e-02 -2.92841978e-02 ...  3.19150500e-02\n",
      "    2.15588807e-04 -1.37220323e-01]\n",
      "  [ 1.98281836e-03 -5.19152842e-02  3.46726105e-02 ...  9.66160223e-02\n",
      "    6.45988679e-04 -1.22503825e-01]\n",
      "  ...\n",
      "  [ 8.69954303e-02  1.40484586e-01 -1.00640230e-01 ... -6.21275939e-02\n",
      "    1.11477129e-04 -4.74909507e-02]\n",
      "  [ 1.35485396e-01  7.25948140e-02  9.15922038e-03 ...  2.00437550e-02\n",
      "    3.79537058e-04  1.67382434e-02]\n",
      "  [ 8.32025930e-02  1.02553532e-01 -5.33023924e-02 ...  4.97835726e-02\n",
      "    4.39581845e-06  5.71296588e-02]]], shape=(1, 12, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 入力例\n",
    "text_input = tokenizer('I am a Ironman.', return_tensors='tf', padding='max_length', max_length=15).input_ids\n",
    "visual_input = tf.random.uniform((1, 3, 224, 224), minval=-1, maxval=1)\n",
    "visual_embedding = vit(visual_input).last_hidden_state\n",
    "\n",
    "# テキスト入力をT5エンコーダーで埋め込みに変換\n",
    "text_embedding = t5.encoder(input_ids=text_input).last_hidden_state\n",
    "\n",
    "# デコーダの入力用IDを作成\n",
    "decoder_input_ids = tokenizer('translate English to German: This is a test.', return_tensors='tf').input_ids\n",
    "\n",
    "# VQAモデルを作成\n",
    "model = VQAModel(t5)\n",
    "\n",
    "# 予測\n",
    "output = model([visual_embedding, text_embedding, decoder_input_ids])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.84944905e-02  9.05140862e-02 -1.20279394e-01 ...  6.31373525e-02\n",
      "  -3.64452512e-06 -1.87197119e-01]\n",
      " [-1.64691042e-02  4.84788939e-02 -2.92841978e-02 ...  3.19150500e-02\n",
      "   2.15588807e-04 -1.37220323e-01]\n",
      " [ 1.98281836e-03 -5.19152842e-02  3.46726105e-02 ...  9.66160223e-02\n",
      "   6.45988679e-04 -1.22503825e-01]\n",
      " ...\n",
      " [ 8.69954303e-02  1.40484586e-01 -1.00640230e-01 ... -6.21275939e-02\n",
      "   1.11477129e-04 -4.74909507e-02]\n",
      " [ 1.35485396e-01  7.25948140e-02  9.15922038e-03 ...  2.00437550e-02\n",
      "   3.79537058e-04  1.67382434e-02]\n",
      " [ 8.32025930e-02  1.02553532e-01 -5.33023924e-02 ...  4.97835726e-02\n",
      "   4.39581845e-06  5.71296588e-02]], shape=(12, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: [100, 19, 3, 9, 3106, 3785, 1]\n",
      "Tokens: ['▁This', '▁is', '▁', 'a', '▁sample', '▁input', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# 埋め込みをトークンIDに逆変換する\n",
    "token_ids = tokenizer.encode(\"This is a sample input\")\n",
    "print(\"Token IDs:\", token_ids)\n",
    "\n",
    "# トークンIDをトークンに変換する\n",
    "tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "print(\"Tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " visual_embedding (InputLayer)  [(None, 197, 768)]   0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 197, 512)     393728      ['visual_embedding[0][0]']       \n",
      "                                                                                                  \n",
      " text_embedding (InputLayer)    [(None, 15, 512)]    0           []                               \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, 197, 512)     0           ['dense[0][0]',                  \n",
      "                                                                  'text_embedding[0][0]']         \n",
      "                                                                                                  \n",
      " decoder_input_ids (InputLayer)  [(None, None)]      0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 212, 512)     0           ['attention[0][0]',              \n",
      "                                                                  'text_embedding[0][0]']         \n",
      "                                                                                                  \n",
      " decoder (TFT5MainLayer)        TFBaseModelOutputWi  41625344    ['decoder_input_ids[0][0]',      \n",
      "                                thPastAndCrossAtten               'concatenate[0][0]']            \n",
      "                                tions(last_hidden_s                                               \n",
      "                                tate=(None, None, 5                                               \n",
      "                                12),                                                              \n",
      "                                 past_key_values=((                                               \n",
      "                                (None, 8, None, 64)                                               \n",
      "                                , (None, 8, None, 6                                               \n",
      "                                4),                                                               \n",
      "                                 (None, 8, None, 64                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 8, None, 64                                               \n",
      "                                )),                                                               \n",
      "                                 ((None, 8, None, 6                                               \n",
      "                                4),                                                               \n",
      "                                 (None, 8, None, 64                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 8, None, 64                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 8, None, 64                                               \n",
      "                                )),                                                               \n",
      "                                 ((None, 8, None, 6                                               \n",
      "                                4),                                                               \n",
      "                                 (None, 8, None, 64                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 8, None, 64                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 8, None, 64                                               \n",
      "                                )),                                                               \n",
      "                                 ((None, 8, None, 6                                               \n",
      "                                4),                                                               \n",
      "                                 (None, 8, None, 64                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 8, None, 64                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 8, None, 64                                               \n",
      "                                )),                                                               \n",
      "                                 ((None, 8, None, 6                                               \n",
      "                                4),                                                               \n",
      "                                 (None, 8, None, 64                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 8, None, 64                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 8, None, 64                                               \n",
      "                                )),                                                               \n",
      "                                 ((None, 8, None, 6                                               \n",
      "                                4),                                                               \n",
      "                                 (None, 8, None, 64                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 8, None, 64                                               \n",
      "                                ),                                                                \n",
      "                                 (None, 8, None, 64                                               \n",
      "                                ))),                                                              \n",
      "                                 hidden_states=None                                               \n",
      "                                , attentions=None,                                                \n",
      "                                cross_attentions=No                                               \n",
      "                                ne)                                                               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 42,019,072\n",
      "Trainable params: 42,019,072\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "#plot_model(model, to_file='model_vit.png')\n",
    "plot_model(model, to_file='model_t5.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-17 13:37:05.067088: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-17 13:37:05.067145: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-17 13:37:05.068169: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-17 13:37:05.074690: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-17 13:37:05.954428: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/data/t32303m/anaconda3/envs/KIBU3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>question_preprocessed</th>\n",
       "      <th>answer_preprocessed</th>\n",
       "      <th>answers</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train2014/COCO_train2014_000000458752.jpg</td>\n",
       "      <td>is this man a professional baseball player</td>\n",
       "      <td>yes</td>\n",
       "      <td>['yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes...</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train2014/COCO_train2014_000000524291.jpg</td>\n",
       "      <td>is the dog waiting</td>\n",
       "      <td>yes</td>\n",
       "      <td>['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'ye...</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train2014/COCO_train2014_000000393221.jpg</td>\n",
       "      <td>is the sky blue</td>\n",
       "      <td>yes</td>\n",
       "      <td>['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'ye...</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    image_id  \\\n",
       "0  train2014/COCO_train2014_000000458752.jpg   \n",
       "1  train2014/COCO_train2014_000000524291.jpg   \n",
       "2  train2014/COCO_train2014_000000393221.jpg   \n",
       "\n",
       "                        question_preprocessed answer_preprocessed  \\\n",
       "0  is this man a professional baseball player                 yes   \n",
       "1                          is the dog waiting                 yes   \n",
       "2                             is the sky blue                 yes   \n",
       "\n",
       "                                             answers  class_label  \n",
       "0  ['yes', 'yes', 'yes', 'yes', 'yes', 'no', 'yes...          995  \n",
       "1  ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'ye...          995  \n",
       "2  ['yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'ye...          995  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import T5Tokenizer, TFT5Model, ViTImageProcessor, TFViTModel\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.layers import Permute\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# データセットの読み込み\n",
    "data_df_k1000 = pd.read_csv(\"./0Data/mscoco_train2014_preprocessed_k1000.csv\")\n",
    "data_df_k1000.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (388272, 3)\n",
      "y.shape: (388272,)\n"
     ]
    }
   ],
   "source": [
    "X = data_df_k1000[['image_id','question_preprocessed', 'answer_preprocessed']]\n",
    "#y = data_df_k1000['class_label']\n",
    "y = data_df_k1000['answer_preprocessed']\n",
    "print('X.shape:',X.shape)\n",
    "print('y.shape:',y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314499, 3) (314499,)\n",
      "(38828, 3) (38828,)\n",
      "(34945, 3) (34945,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# perform train validation & test split on the dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.10, stratify=y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.10, stratify=y_train, random_state=42)\n",
    "\n",
    "\n",
    "#X_train,y_train = pickle.load(open('./0Data/train_1129.pkl', 'rb'))\n",
    "#X_val,y_val = pickle.load(open('./0Data/val_1129.pkl', 'rb'))\n",
    "#X_test,y_test = pickle.load(open('./0Data/test_1129.pkl', 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 前処理関数\n",
    "# def preprocess_data(row, tokenizer, vit_processor, image_dir):\n",
    "#     image_path = f\"{image_dir}/{row['image_id']}\"\n",
    "#     question = row['question_preprocessed']\n",
    "#     answer = row['answer_preprocessed']\n",
    "\n",
    "#     # 画像の前処理\n",
    "#     # image = tf.io.read_file(image_path)\n",
    "#     # image = tf.image.decode_jpeg(image, channels=3)\n",
    "#     # image = tf.image.resize(image, [224, 224])\n",
    "#     # image = tf.cast(image, tf.float32) / 255.0  # 正規化\n",
    "#     image = cv2.imread(image_path)\n",
    "#     image = cv2.resize(image, (224,224))\n",
    "#     image = np.array(image) / 255.0\n",
    "#     #image = vit_processor(images=image, return_tensors=\"tf\").pixel_values\n",
    "    \n",
    "#     # image = cv2.imread(image_path)\n",
    "#     # image = cv2.resize(image, (224,224))\n",
    "#     # image = np.array(image) / 255.0\n",
    "\n",
    "#     # 質問のトークン化\n",
    "#     question_tokens = tokenizer(question, return_tensors='tf', padding='max_length', max_length=15).input_ids\n",
    "\n",
    "#     # 答えのトークン化\n",
    "#     answer_tokens = tokenizer(answer, return_tensors='tf').input_ids\n",
    "\n",
    "#     return image, question_tokens, answer_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_data(row, tokenizer, vit_processor, image_dir):\n",
    "#     image_path = f\"{image_dir}/{row['image_id']}\"\n",
    "#     question = row['question_preprocessed']\n",
    "#     answer = row['answer_preprocessed']\n",
    "\n",
    "#     # 画像の前処理\n",
    "#     image = cv2.imread(image_path)\n",
    "#     if image is None:\n",
    "#         raise ValueError(f\"Image not found at path: {image_path}\")\n",
    "#     image = cv2.resize(image, (224, 224))\n",
    "#     image = image.astype(np.float32) / 255.0  # 正規化\n",
    "\n",
    "#     # ViTプロセッサーで前処理を行う\n",
    "#     #image = vit_processor(images=image, return_tensors=\"tf\").pixel_values\n",
    "\n",
    "#     # 質問のトークン化\n",
    "#     question_tokens = tokenizer(question, return_tensors='tf', padding='max_length', max_length=15).input_ids\n",
    "\n",
    "#     # 答えのトークン化\n",
    "#     answer_tokens = tokenizer(answer, return_tensors='tf').input_ids\n",
    "\n",
    "#     return image, question_tokens, answer_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# # 前処理用のトークナイザーとViTプロセッサーの準備\n",
    "pretrained_t5_path = 'google-t5/t5-small'\n",
    "# pretrained_vit_path = 'google/vit-base-patch16-224-in21k'\n",
    "tokenizer = T5Tokenizer.from_pretrained(pretrained_t5_path)\n",
    "# vit_processor = ViTImageProcessor.from_pretrained(pretrained_vit_path)\n",
    "\n",
    "# データセットのパス\n",
    "image_dir = \"./0Data/MSCOCO/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class DataGenerator(tf.keras.utils.Sequence):\n",
    "#     def __init__(self, df, image_dir, batch_size, tokenizer, vit_processor, max_seq_length=15):\n",
    "#         self.df = df\n",
    "#         self.image_dir = image_dir\n",
    "#         self.batch_size = batch_size\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.vit_processor = vit_processor\n",
    "#         self.max_seq_length = max_seq_length\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return int(np.floor(len(self.df) / self.batch_size))\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         batch_x0 = self.df.iloc[index * self.batch_size:(index + 1) * self.batch_size, 1].values\n",
    "#         batch_x1 = self.df.iloc[index * self.batch_size:(index + 1) * self.batch_size, 0].values\n",
    "#         batch_y = self.df.iloc[index * self.batch_size:(index + 1) * self.batch_size, 2].values\n",
    "\n",
    "#         X0_batch = np.asarray([self.__get_input1(que) for que in batch_x0])\n",
    "#         X1_batch = np.asarray([self.__get_input2(self.image_dir + path) for path in batch_x1])\n",
    "#         y_batch = np.asarray([self.__get_output(answer) for answer in batch_y])\n",
    "\n",
    "#         return (X1_batch, X0_batch, y_batch), y_batch\n",
    "\n",
    "#     def on_epoch_end(self):\n",
    "#         pass\n",
    "\n",
    "#     def __get_input1(self, question):\n",
    "#         question_tokens = self.tokenizer(question, return_tensors='tf', padding='max_length', max_length=self.max_seq_length).input_ids\n",
    "#         return question_tokens.numpy().flatten()\n",
    "\n",
    "#     def __get_input2(self, image_path):\n",
    "#         image = cv2.imread(image_path)\n",
    "#         image = cv2.resize(image, (224, 224))\n",
    "#         image = image.astype(np.float32) / 255.0\n",
    "#         image = self.vit_processor(images=image, return_tensors=\"tf\").pixel_values\n",
    "#         return image.numpy().flatten()\n",
    "\n",
    "#     def __get_output(self, answer):\n",
    "#         answer_tokens = self.tokenizer(answer, return_tensors='tf', padding='max_length', max_length=self.max_seq_length).input_ids\n",
    "#         return answer_tokens.numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # データジェネレータの初期化\n",
    "# traingen = DataGenerator(X_train, image_dir, batch_size=8, tokenizer=tokenizer, vit_processor=vit_processor)\n",
    "# valgen = DataGenerator(X_val, image_dir, batch_size=8, tokenizer=tokenizer, vit_processor=vit_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, X_que, X_img, y,\n",
    "                 batch_size,\n",
    "                 shuffle=True):\n",
    "\n",
    "        self.X_que = X_que\n",
    "        self.X_img = X_img\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(y))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)\n",
    "\n",
    "    def __get_input1(self, que):\n",
    "        question_tokens = tokenizer(que, return_tensors='tf', padding='max_length', max_length=30).input_ids\n",
    "        text_embedding = t5.encoder(input_ids=question_tokens).last_hidden_state\n",
    "        text_embedding = tf.squeeze(text_embedding, axis=0)\n",
    "        return text_embedding\n",
    "\n",
    "    def __get_input2(self, path):\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = np.array(img) / 255.0\n",
    "        #img = np.expand_dims(img, axis=0)\n",
    "        return img\n",
    "\n",
    "    def __get_output(self, answer):\n",
    "        answer_tokens = tokenizer(answer, return_tensors='tf', padding='max_length', max_length=30).input_ids\n",
    "        return answer_tokens\n",
    "    \n",
    "    def __get_decoder_input_ids(self, answer):\n",
    "        # T5のデコーダ入力は通常、<pad>トークンで初期化されたシーケンス\n",
    "        decoder_input_ids = tokenizer('<pad>', return_tensors='tf', padding='max_length', max_length=30, truncation=True).input_ids\n",
    "        return decoder_input_ids.numpy().squeeze()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_x0 = self.X_que[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_x1 = self.X_img[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_y = self.y[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        X0_batch = np.asarray([self.__get_input1(que) for que in batch_x0])\n",
    "        X1_batch = np.asarray([self.__get_input2(image_dir + path) for path in batch_x1])\n",
    "        y_batch = np.asarray([self.__get_output(answer) for answer in batch_y])\n",
    "        decoder_input_ids_batch = np.array([self.__get_decoder_input_ids(answer) for answer in batch_y])\n",
    "        return tuple([X1_batch,X0_batch, decoder_input_ids_batch]), y_batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indexes) // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_siz = 128\n",
    "traingen = CustomDataGen(list(X_train['question_preprocessed']),list(X_train['image_id']),list(y_train),batch_size=batch_siz)\n",
    "valgen = CustomDataGen(list(X_val['question_preprocessed']),list(X_val['image_id']),list(y_val),batch_size=batch_siz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # データの前処理\n",
    "# processed_data = X.apply(lambda row: preprocess_data(row, tokenizer, vit_processor, image_dir), axis=1)\n",
    "# # processed_data = data_df_k1000.apply(lambda row: preprocess_data(row, tokenizer, vit_processor, image_dir), axis=1)\n",
    "# images, questions, answers = zip(*processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # データの前処理\n",
    "# processed_data = X_test.apply(lambda row: preprocess_data(row, tokenizer, vit_processor, image_dir), axis=1)\n",
    "# images, questions, answers = zip(*processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # データセットの作成\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((list(images), list(questions), list(answers)))\n",
    "\n",
    "# # バッチ処理\n",
    "# batch_size = 8\n",
    "# dataset = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# VQAModelの再定義\n",
    "def VQAModel(t5, vit):\n",
    "    inputs = Input(shape=(224, 224, 3))\n",
    "    x = Permute((3, 1, 2))(inputs)\n",
    "    visual_embedding = vit(x).last_hidden_state\n",
    "    #visual_embedding_shape = (197, 768)\n",
    "    text_embedding_shape = (30, 512)\n",
    "    \n",
    "    #visual_embedding = Input(visual_embedding_shape, name='visual_embedding')\n",
    "    text_embedding = Input(text_embedding_shape, name='text_embedding')\n",
    "\n",
    "    # 視覚埋め込みをテキスト埋め込みの次元に合わせて変換\n",
    "    x_v = layers.Dense(\n",
    "        units=text_embedding_shape[-1], \n",
    "        activation='relu', \n",
    "        use_bias=True,\n",
    "    )(visual_embedding)\n",
    "    \n",
    "    # 注意機構を適用して視覚とテキストの埋め込みを組み合わせる\n",
    "    attention_output = layers.Attention()([x_v, text_embedding])\n",
    "    \n",
    "    # 出力を結合\n",
    "    x = layers.Concatenate(axis=1)([attention_output, text_embedding])\n",
    "\n",
    "    # 結合された埋め込みをT5デコーダに入力するためのエンコードを行う\n",
    "    #decoder_input_ids = layers.Input(shape=(None,), dtype=tf.int32, name='decoder_input_ids')\n",
    "    decoder_input_ids = tf.constant([[tokenizer.pad_token_id]])\n",
    "    t5_output = t5.decoder(input_ids=decoder_input_ids, encoder_hidden_states=x).last_hidden_state\n",
    "    print(t5_output)\n",
    "\n",
    "    return Model(inputs=[inputs, text_embedding, decoder_input_ids], outputs=t5_output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFT5Model.\n",
      "\n",
      "All the weights of TFT5Model were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5Model for predictions without further training.\n",
      "All PyTorch model weights were used when initializing TFViTModel.\n",
      "\n",
      "All the weights of TFViTModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(1, 1, 512), dtype=tf.float32, name=None), name='decoder/dropout_1400/Identity_1:0', description=\"created by layer 'decoder'\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: [[0]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m vit \u001b[38;5;241m=\u001b[39m TFViTModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_vit_path)\n\u001b[1;32m      7\u001b[0m vit\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mVQAModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# # Compile the model\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\u001b[39;00m\n",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36mVQAModel\u001b[0;34m(t5, vit)\u001b[0m\n\u001b[1;32m     29\u001b[0m t5_output \u001b[38;5;241m=\u001b[39m t5\u001b[38;5;241m.\u001b[39mdecoder(input_ids\u001b[38;5;241m=\u001b[39mdecoder_input_ids, encoder_hidden_states\u001b[38;5;241m=\u001b[39mx)\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(t5_output)\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt5_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/KIBU3/lib/python3.9/site-packages/tensorflow/python/trackable/base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/KIBU3/lib/python3.9/site-packages/keras/src/engine/functional.py:158\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Check if the inputs contain any intermediate `KerasTensor` (not\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# created by tf.keras.Input()). In this case we need to clone the `Node`\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# and `KerasTensor` objects to mimic rebuilding a new model from new\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# inputs.  This feature is only enabled in TF2 not in v1 graph mode.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m--> 158\u001b[0m         [\n\u001b[1;32m    159\u001b[0m             functional_utils\u001b[38;5;241m.\u001b[39mis_input_keras_tensor(t)\n\u001b[1;32m    160\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[1;32m    161\u001b[0m         ]\n\u001b[1;32m    162\u001b[0m     ):\n\u001b[1;32m    163\u001b[0m         inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(\n\u001b[1;32m    164\u001b[0m             inputs, outputs\n\u001b[1;32m    165\u001b[0m         )\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/KIBU3/lib/python3.9/site-packages/keras/src/engine/functional.py:159\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Check if the inputs contain any intermediate `KerasTensor` (not\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# created by tf.keras.Input()). In this case we need to clone the `Node`\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# and `KerasTensor` objects to mimic rebuilding a new model from new\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# inputs.  This feature is only enabled in TF2 not in v1 graph mode.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    158\u001b[0m         [\n\u001b[0;32m--> 159\u001b[0m             \u001b[43mfunctional_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_input_keras_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[1;32m    161\u001b[0m         ]\n\u001b[1;32m    162\u001b[0m     ):\n\u001b[1;32m    163\u001b[0m         inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(\n\u001b[1;32m    164\u001b[0m             inputs, outputs\n\u001b[1;32m    165\u001b[0m         )\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/KIBU3/lib/python3.9/site-packages/keras/src/engine/functional_utils.py:48\u001b[0m, in \u001b[0;36mis_input_keras_tensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check if tensor is directly generated from `tf.keras.Input`.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03mThis check is useful when constructing the functional model, since we will\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m  ValueError: if the tensor is not a KerasTensor instance.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m node_module\u001b[38;5;241m.\u001b[39mis_keras_tensor(tensor):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_KERAS_TENSOR_TYPE_CHECK_ERROR_MSG\u001b[38;5;241m.\u001b[39mformat(tensor))\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mis_input\n",
      "\u001b[0;31mValueError\u001b[0m: Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: [[0]]"
     ]
    }
   ],
   "source": [
    "\n",
    "# モデルの作成\n",
    "pretrained_t5_path = 'google-t5/t5-small'\n",
    "pretrained_vit_path = 'google/vit-base-patch16-224-in21k'\n",
    "\n",
    "t5 = TFT5Model.from_pretrained(pretrained_t5_path)\n",
    "vit = TFViTModel.from_pretrained(pretrained_vit_path)\n",
    "vit.trainable = False\n",
    "\n",
    "model = VQAModel(t5, vit)\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "# metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFT5Model.\n",
      "\n",
      "All the weights of TFT5Model were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5Model for predictions without further training.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFT5ForConditionalGeneration\n",
    "model = TFT5Model.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\").input_ids\n",
    "output = model(inputs, decoder_input_ids=inputs)\n",
    "last_hidden_states = output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFT5Model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\")\n",
    "model = TFT5Model.from_pretrained(\"google-t5/t5-small\")\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    \"Studies have been shown that owning a dog is good for you\", return_tensors=\"tf\"\n",
    ").input_ids  # Batch size 1\n",
    "decoder_input_ids = tokenizer(\"Studies show that\", return_tensors=\"tf\").input_ids  # Batch size 1\n",
    "\n",
    "# preprocess: Prepend decoder_input_ids with start token which is pad token for T5Model.\n",
    "# This is not needed for torch's T5ForConditionalGeneration as it does this internally using labels arg.\n",
    "decoder_input_ids = model._shift_right(decoder_input_ids)\n",
    "\n",
    "# forward pass\n",
    "outputs = model(input_ids, decoder_input_ids=decoder_input_ids)\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "All PyTorch model weights were used when initializing TFT5Model.\n",
      "\n",
      "All the weights of TFT5Model were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5Model for predictions without further training.\n",
      "/data/t32303m/anaconda3/envs/KIBU3/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5.py:303: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# # from transformers import T5Tokenizer, TFT5Model\n",
    "\n",
    "# tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "# model = TFT5Model.from_pretrained('t5-small')\n",
    "# # inputs = tokenizer.encode(\"Hello, my dog is cute\", return_tensors=\"tf\")  # Batch size 1\n",
    "# # outputs = model(inputs, decoder_input_ids=inputs)\n",
    "# # last_hidden_states = outputs[0]\n",
    "\n",
    "# inputs = tokenizer.encode(\"translate English to German: The house is wonderful. </s>\", return_tensors=\"tf\")\n",
    "# decoder_input_ids  = tokenizer.encode(\"Das Haus ist wunderbar. </s>\", return_tensors=\"tf\")\n",
    "# outputs = model(inputs, decoder_input_ids =decoder_input_ids )\n",
    "# last_hidden_states = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 1.48529354e-02 -9.22696590e-02  9.37008485e-02  1.43680558e-01\n",
      " -2.11895513e-03  6.88846186e-02 -3.12835097e-01 -9.99857560e-02\n",
      "  8.53669420e-02  2.99759060e-02 -3.08242384e-02  9.01191086e-02\n",
      " -5.20973019e-02  7.66383260e-02  4.63347054e+00  6.52005672e-02\n",
      "  3.05472277e-02  6.17499053e-02 -2.24359222e-02  2.67952513e-02\n",
      "  3.26223895e-02  1.12931065e-01  3.50049771e-02  2.43807703e-01\n",
      "  6.82013156e-03 -1.39531091e-01  8.68418738e-02  7.95792639e-01\n",
      "  9.35113952e-02 -9.15320143e-02  5.64946309e-02 -2.89967507e-01\n",
      "  3.61749008e-02 -8.24128836e-02  1.27326596e+00 -1.13218799e-01\n",
      "  8.60494822e-02 -5.84218539e-02 -4.03499044e-02 -6.50982335e-02\n",
      " -3.72635126e-02 -4.57082242e-02  1.40368521e-01 -9.81302783e-02\n",
      " -4.91393544e-02 -6.21563662e-03 -1.66676804e-01  6.34316429e-02\n",
      " -3.42578553e-02  2.81873383e-02  1.40079543e-01  1.30399957e-01\n",
      " -1.01335518e-01  1.16877675e-01 -1.23612769e-01  1.15672387e-01\n",
      "  1.56304650e-02 -1.00149950e-02  3.16154957e-02  3.43137309e-02\n",
      " -6.42459616e-02 -6.91959858e-02  1.98467165e-01  3.83367166e-02\n",
      "  4.41954024e-02  6.96185455e-02  4.70926166e-02 -1.39761731e-01\n",
      " -1.59430429e-02  1.85963690e-01  5.45250401e-02 -5.24535738e-02\n",
      "  2.49122903e-02 -1.04140900e-01  5.78607619e-02  7.22884154e-03\n",
      "  2.35729124e-02 -2.34110504e-02  2.31509000e-01  7.91562647e-02\n",
      " -1.18190199e-01  2.94342693e-02 -9.57932100e-02 -4.21474949e-02\n",
      " -1.00748152e-01  1.99790318e-02 -1.50283389e-02  1.06234267e-01\n",
      " -1.20472841e-01  3.37537704e-03 -3.76797505e-02 -1.95935488e-01\n",
      "  5.75036509e-03 -4.83269878e-02 -1.04472511e-01  3.56205227e-03\n",
      " -3.08172792e-01  3.16327177e-02 -1.08612422e-02 -1.57237072e-02\n",
      " -3.03367265e-02  6.49737939e-02  1.40042022e-01  2.90566206e-01\n",
      "  1.34822233e-02  1.25836749e-02 -7.03143328e-02 -6.82757571e-02\n",
      "  2.44925674e-02  5.42790368e-02  2.80322321e-02  1.39196903e-01\n",
      " -3.68267894e-02  6.65989965e-02  1.54582607e-02  8.04068521e-02\n",
      " -2.52686907e-03  7.52987191e-02  1.57228068e-01  1.44926399e-01\n",
      " -8.04027766e-02 -1.18595578e-01 -5.28995991e-02  1.21410519e-01\n",
      "  6.04158826e-02  6.44165501e-02  8.08806643e-02 -1.09030105e-01\n",
      " -1.99391451e-02  2.78685596e-02 -1.84725598e-01 -7.49764293e-02\n",
      "  1.17359757e-01  1.43263722e-02 -7.00699538e-02  2.23638453e-02\n",
      " -3.13869596e-01  8.53126287e-01 -3.14441882e-02  6.61449879e-02\n",
      " -4.43085376e-03 -1.43513471e-01 -4.21537012e-02 -1.84236653e-02\n",
      " -6.72245249e-02  5.43427169e-02 -1.00181699e-02 -3.71080413e-02\n",
      " -4.25511152e-02 -5.69727707e+00  9.42470413e-03  6.38092533e-02\n",
      " -6.72045350e-02  1.46904429e-02  8.07616413e-02  6.59017637e-02\n",
      "  9.57247615e-03  2.13132873e-01  1.77589078e-02 -6.82164431e-01\n",
      "  3.72373941e-03  2.02122971e-01 -8.88426453e-02 -6.83828490e-03\n",
      "  3.46452743e-02  1.26656443e-01 -1.71818450e-01 -3.98726352e-02\n",
      "  1.29130818e-02  1.32893726e-01 -1.23340771e-01  1.32162988e-01\n",
      " -1.04599539e-03 -1.55230444e-02 -1.65060721e-02  6.89759701e-02\n",
      "  7.19415396e-02  2.22016811e-01  4.41721641e-02  1.03538051e-01\n",
      " -5.87155670e-02  7.13536441e-02  7.76020484e-03  2.41331741e-01\n",
      " -1.65636316e-01 -9.40346718e-02  7.70838782e-02  7.50746503e-02\n",
      "  8.61273706e-02 -4.15098108e-02 -3.67154312e+00 -2.73876250e-01\n",
      "  1.23814516e-01  1.36022627e-01 -1.85372055e-01 -1.36868328e-01\n",
      " -1.56878866e-02  8.65304470e-03 -1.16361126e-01  7.64459521e-02\n",
      " -5.20071760e-02 -1.23248026e-01 -3.12608331e-02  8.36670622e-02\n",
      " -2.29459200e-02 -6.43094396e-03 -8.29051062e-03 -2.67607551e-02\n",
      "  8.92568082e-02 -5.28057292e-03  4.84728999e-02 -1.43236950e-01\n",
      " -1.79121960e-02 -1.85526446e-01  8.22504535e-02 -5.74209318e-02\n",
      "  5.09371608e-02 -9.58790705e-02  1.76473752e-01 -1.94885824e-02\n",
      "  2.31794594e-03 -2.24286714e-03  1.51097938e-01  1.28939629e-01\n",
      " -2.08413810e-01 -1.51277967e-02 -8.18501651e-01  1.86146230e-01\n",
      "  4.31884006e-02  9.07772556e-02 -2.71722190e-02 -2.52315886e-02\n",
      " -6.49838001e-02 -3.49120721e-02 -9.13243234e-01 -3.69511917e-02\n",
      "  4.46129479e-02 -9.47766006e-02  1.48769572e-01  1.53287262e-01\n",
      "  1.14003718e-01 -4.28867966e-01  9.06431153e-02  2.95793340e-02\n",
      " -6.92763269e-01  7.35881150e-01  1.34714767e-01  7.46163651e-02\n",
      " -2.51657218e-01 -4.07305127e-03 -1.03627264e-01 -4.20290679e-02\n",
      "  7.51059353e-02  3.98749448e-02 -3.57029624e-02 -5.60838059e-02\n",
      "  4.85725775e-02 -4.12620716e-02 -2.36096188e-01  1.77407842e-02\n",
      " -1.45709766e-02  8.89501944e-02 -2.46705469e-02  2.60805756e-01\n",
      "  2.73518618e-02  6.31291494e-02 -2.22483948e-02  6.55885860e-02\n",
      " -1.86031051e-02  6.65169535e-03 -7.90244415e-02 -8.33019614e-02\n",
      " -1.76134303e-01  2.74654061e-01  4.60500009e-02 -6.12833686e-02\n",
      "  8.90261214e-03  1.93662718e-02  7.44017586e-02 -2.54981648e-02\n",
      "  1.56101525e-01 -1.33285552e-01 -9.68467258e-03  4.89024892e-02\n",
      " -3.20829153e-02 -2.65522059e-02 -5.09734228e-02 -8.21095631e-02\n",
      " -1.00300156e-01 -4.69626347e-03  3.33984718e-02  8.82089734e-02\n",
      " -2.23810896e-02 -5.90120405e-02 -1.99025050e-01  9.53101814e-02\n",
      " -6.77678660e-02  1.29261658e-01  6.67898655e-02  1.27787948e+00\n",
      " -1.00399934e-01 -1.93515867e-02  8.15505013e-02  3.40095870e-02\n",
      " -2.24298403e-01 -1.08767115e-02  7.79092405e-03  8.05269331e-02\n",
      "  2.70973945e+00 -6.49803206e-02 -5.42846741e-04 -7.07197636e-02\n",
      "  1.78652555e-02  2.55714078e-03 -1.37088910e-01 -9.87897888e-02\n",
      " -3.03999446e-02 -4.76816623e-03  1.04809284e-01 -4.68784571e-02\n",
      " -2.12237258e-02  5.40567189e-02 -2.65671052e-02 -3.86513114e-01\n",
      "  1.50842637e-01 -5.06151132e-02  9.26847905e-02  3.97889083e-03\n",
      " -3.50168943e-02 -2.03365251e-01  9.73086059e-02 -8.20980072e-02\n",
      "  1.35757819e-01 -2.31423508e-02 -2.80395579e-02 -1.00041926e-01\n",
      " -1.39112375e-03  3.02960742e-02 -4.81303632e-02  1.01151578e-02\n",
      " -2.40083300e-02 -1.17569968e-01 -4.21938719e-03 -2.92576373e-01\n",
      " -3.43979150e-02 -2.67455205e-02  4.92229499e-02  5.70318941e-03\n",
      "  1.81031618e-02  5.02977055e-03  7.83817247e-02 -2.95049185e-03\n",
      " -2.47564483e-02  7.93724656e-02  6.05578385e-02 -2.15781093e-01\n",
      "  4.61944528e-02  1.04930066e-01 -1.00102857e-01  3.26782241e-02\n",
      " -7.85821769e-03 -5.67450412e-02  4.60841693e-02 -6.11416250e-02\n",
      "  1.34036869e-01  9.02167261e-02 -1.31220762e-02 -1.19825304e-01\n",
      " -3.72114331e-02 -6.98358659e-03 -9.26735103e-02  2.97596678e-02\n",
      " -1.03836663e-01 -5.79460785e-02  3.15304190e-01 -6.55023009e-02\n",
      "  4.74911295e-02 -7.09930882e-02  9.33687687e-02  8.65285750e-04\n",
      "  1.41216088e-02 -3.89064997e-01 -9.53293964e-02 -3.35799269e-02\n",
      "  2.62390852e-01  5.93321323e-02  8.35273266e-01 -7.67953554e-03\n",
      " -4.05343771e-01 -3.03296689e-02 -1.98750086e-02 -2.00720597e-02\n",
      " -8.51272196e-02  2.95865652e-03 -2.30256245e-02  6.63975673e-03\n",
      "  1.62073225e-01  2.27776676e-01 -1.05425939e-02 -4.54835501e-03\n",
      " -1.20437965e-01 -1.41166776e-01 -3.33960682e-01 -1.23270653e-01\n",
      " -2.88633164e-02 -8.60722810e-02 -7.17238262e-02 -6.74637780e-02\n",
      " -1.07252393e-02 -1.25249416e-01  1.55846909e-01  8.22941214e-02\n",
      "  1.69649512e-01  8.19591433e-02  1.97400581e-02 -6.53099874e-03\n",
      "  1.91174895e-01  7.33610764e-02  5.34648821e-02 -5.31687774e-03\n",
      "  6.52139038e-02 -7.45801777e-02 -1.02066480e-01  9.86180231e-02\n",
      "  9.83930230e-02 -2.27031950e-02 -4.27356325e-02  4.66602156e-03\n",
      "  1.65591110e-02 -4.08158191e-02  6.90171570e-02 -2.61808578e-02\n",
      "  1.44274682e-02 -2.88585369e-02 -2.29536444e-02 -5.86848333e-03\n",
      " -2.16699541e-02 -1.41299609e-02  3.88435146e-04 -1.29439473e-01\n",
      "  4.40745577e-02 -3.16574029e-03 -1.29129114e-02  1.85683537e-02\n",
      "  3.20029296e-02  9.60378721e-02  1.25151752e-02 -1.50653660e-01\n",
      "  1.65367667e-02  2.74012089e-02  4.40801121e-02 -8.11287761e-02\n",
      " -3.31737548e-02 -1.34698763e-01  3.64271253e-02  5.09158634e-02\n",
      "  1.73633487e-03  4.09452543e-02 -2.01981366e-02 -3.29071730e-02\n",
      " -1.05419662e-02  1.86785664e-02 -9.15187970e-02  4.55480181e-02\n",
      "  1.27276286e-01  5.76883294e-02 -4.81079891e-02  1.75923109e-02\n",
      " -3.42150517e-02  4.74022403e-02  4.81121875e-02  5.60865588e-02\n",
      " -8.40971172e-02 -2.04411261e-02  2.70634908e-02 -4.57562298e-01\n",
      "  2.88658179e-02 -7.95277178e-01 -9.56061035e-02 -3.46349254e-02\n",
      " -8.16658586e-02  4.95243967e-02 -3.31042707e-02 -6.79109022e-02\n",
      "  1.09455399e-01 -3.93774826e-03 -2.50064228e-02  1.15110666e-01\n",
      "  4.04437594e-02  7.48697370e-02  1.26622943e-03 -7.95672357e-04\n",
      "  7.91855680e-04 -4.34810808e-03  2.71112937e-02 -3.17289643e-02\n",
      " -7.46121705e-02 -3.08169425e-01 -9.35474504e-03  4.01336141e-02\n",
      "  4.48801741e-02 -2.62055621e-02  6.19944893e-02 -6.02710620e-02\n",
      " -1.52483881e-01  1.28004234e-02  1.31822368e-02 -3.44332494e-02\n",
      "  5.05713373e-02 -1.20073929e-02  1.62701326e-04  1.57032788e-01], shape=(512,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(last_hidden_states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " permute (Permute)           (None, 3, 224, 224)          0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf_vi_t_model (TFViTModel)  TFBaseModelOutputWithPooli   8638924   ['permute[0][0]']             \n",
      "                             ng(last_hidden_state=(None   8                                       \n",
      "                             , 197, 768),                                                         \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , hidden_states=None, atte                                           \n",
      "                             ntions=None)                                                         \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 197, 512)             393728    ['tf_vi_t_model[0][0]']       \n",
      "                                                                                                  \n",
      " text_embedding (InputLayer  [(None, 30, 512)]            0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, 197, 512)             0         ['dense[0][0]',               \n",
      "                                                                     'text_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " decoder_input_ids (InputLa  [(None, None)]               0         []                            \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 227, 512)             0         ['attention[0][0]',           \n",
      "                                                                     'text_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " decoder (TFT5MainLayer)     TFBaseModelOutputWithPastA   4162534   ['decoder_input_ids[0][0]',   \n",
      "                             ndCrossAttentions(last_hid   4          'concatenate[0][0]']         \n",
      "                             den_state=(None, None, 512                                           \n",
      "                             ),                                                                   \n",
      "                              past_key_values=(((None,                                            \n",
      "                             8, None, 64),                                                        \n",
      "                              (None, 8, None, 64),                                                \n",
      "                              (None, 8, None, 64),                                                \n",
      "                              (None, 8, None, 64)),                                               \n",
      "                              ((None, 8, None, 64),                                               \n",
      "                              (None, 8, None, 64),                                                \n",
      "                              (None, 8, None, 64),                                                \n",
      "                              (None, 8, None, 64)),                                               \n",
      "                              ((None, 8, None, 64),                                               \n",
      "                              (None, 8, None, 64),                                                \n",
      "                              (None, 8, None, 64),                                                \n",
      "                              (None, 8, None, 64)),                                               \n",
      "                              ((None, 8, None, 64),                                               \n",
      "                              (None, 8, None, 64),                                                \n",
      "                              (None, 8, None, 64),                                                \n",
      "                              (None, 8, None, 64)),                                               \n",
      "                              ((None, 8, None, 64),                                               \n",
      "                              (None, 8, None, 64),                                                \n",
      "                              (None, 8, None, 64),                                                \n",
      "                              (None, 8, None, 64)),                                               \n",
      "                              ((None, 8, None, 64),                                               \n",
      "                              (None, 8, None, 64),                                                \n",
      "                              (None, 8, None, 64),                                                \n",
      "                              (None, 8, None, 64))),                                              \n",
      "                              hidden_states=None, atten                                           \n",
      "                             tions=None, cross_attentio                                           \n",
      "                             ns=None)                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 128408320 (489.84 MB)\n",
      "Trainable params: 42019072 (160.29 MB)\n",
      "Non-trainable params: 86389248 (329.55 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "#plot_model(model, to_file='model_vit.png')\n",
    "plot_model(model, to_file='model0614.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 入力例\n",
    "#text_input = \"I am a Ironman.\"\n",
    "text_input = tokenizer('What does she do?', return_tensors='tf', padding='max_length', max_length=30).input_ids\n",
    "text_embedding = t5.encoder(input_ids=text_input).last_hidden_state\n",
    "path = \"./0Data/MSCOCO/train2014/COCO_train2014_000000000110.jpg\"\n",
    "img = cv2.imread(path)\n",
    "img = cv2.resize(img, (224, 224))\n",
    "visual_input = np.array(img) / 255.0\n",
    "visual_input = np.expand_dims(visual_input, axis=0)\n",
    "\n",
    "# visual_input = tf.random.uniform((1, 224, 224, 3), minval=-1, maxval=1)\n",
    "\n",
    "# デコーダの入力用IDを作成\n",
    "decoder_input_ids = tokenizer('<pad>', return_tensors='tf', padding='max_length', max_length=30, truncation=True).input_ids\n",
    "\n",
    "# 予測\n",
    "output = model([visual_input, text_embedding,decoder_input_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill fill']\n"
     ]
    }
   ],
   "source": [
    "# 出力をトークンIDに変換\n",
    "token_ids = tf.argmax(output, axis=-1)\n",
    "\n",
    "# トークンIDを文章にデコード\n",
    "decoded_output = tokenizer.batch_decode(token_ids.numpy(), skip_special_tokens=True)\n",
    "\n",
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint_filepath=\"./0Data/model/gpu/t5_vit_weights-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
    "model_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 17:36:50.434626: I external/local_xla/xla/service/service.cc:168] XLA service 0x5606d1a31ed0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-14 17:36:50.434689: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0\n",
      "2024-06-14 17:36:50.434705: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA A100-SXM4-40GB, Compute Capability 8.0\n",
      "2024-06-14 17:36:50.434718: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA A100-SXM4-40GB, Compute Capability 8.0\n",
      "2024-06-14 17:36:50.434728: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA A100-SXM4-40GB, Compute Capability 8.0\n",
      "2024-06-14 17:36:50.446673: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718354210.650285  189062 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2457/2457 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0992"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/t32303m/anaconda3/envs/KIBU3/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2457/2457 [==============================] - 20089s 8s/step - loss: nan - accuracy: 0.0992 - val_loss: nan - val_accuracy: 0.9464\n",
      "Epoch 2/10\n",
      "2457/2457 [==============================] - 20080s 8s/step - loss: nan - accuracy: 0.0991 - val_loss: nan - val_accuracy: 0.9464\n",
      "Epoch 3/10\n",
      "2457/2457 [==============================] - 20110s 8s/step - loss: nan - accuracy: 0.0992 - val_loss: nan - val_accuracy: 0.9464\n",
      "Epoch 4/10\n",
      "2457/2457 [==============================] - 20134s 8s/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.9464\n",
      "Epoch 5/10\n",
      "2457/2457 [==============================] - 20122s 8s/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.9464\n",
      "Epoch 6/10\n",
      "2457/2457 [==============================] - 20138s 8s/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.9464\n",
      "Epoch 7/10\n",
      "2457/2457 [==============================] - 20128s 8s/step - loss: nan - accuracy: 0.0995 - val_loss: nan - val_accuracy: 0.9464\n",
      "Epoch 8/10\n",
      "2457/2457 [==============================] - 20116s 8s/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.9464\n",
      "Epoch 9/10\n",
      "2457/2457 [==============================] - 20120s 8s/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.9464\n",
      "Epoch 10/10\n",
      "2457/2457 [==============================] - 20148s 8s/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.9464\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(traingen,batch_size=128,epochs=10,verbose=1,validation_data=valgen,callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_vi_t_model/vit/pooler/dense/kernel:0', 'tf_vi_t_model/vit/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_vi_t_model/vit/pooler/dense/kernel:0', 'tf_vi_t_model/vit/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_vi_t_model/vit/pooler/dense/kernel:0', 'tf_vi_t_model/vit/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_vi_t_model/vit/pooler/dense/kernel:0', 'tf_vi_t_model/vit/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 19:43:02.102643: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fa8a8615130 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-13 19:43:02.102705: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0\n",
      "2024-06-13 19:43:02.102712: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA A100-SXM4-40GB, Compute Capability 8.0\n",
      "2024-06-13 19:43:02.102719: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA A100-SXM4-40GB, Compute Capability 8.0\n",
      "2024-06-13 19:43:02.102725: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA A100-SXM4-40GB, Compute Capability 8.0\n",
      "2024-06-13 19:43:02.111146: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718275382.310305   51293 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2457/2457 [==============================] - 22011s 9s/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.9464\n",
      "Epoch 2/100\n",
      "2457/2457 [==============================] - 21869s 9s/step - loss: nan - accuracy: 0.0992 - val_loss: nan - val_accuracy: 0.9464\n",
      "Epoch 3/100\n",
      "2457/2457 [==============================] - ETA: 0s - loss: nan - accuracy: 0.0993"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history\u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraingen\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalgen\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/KIBU3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/KIBU3/lib/python3.9/site-packages/keras/src/engine/training.py:1856\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1842\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1843\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1854\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1855\u001b[0m     )\n\u001b[0;32m-> 1856\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1867\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1868\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1869\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1870\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1871\u001b[0m }\n\u001b[1;32m   1872\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/anaconda3/envs/KIBU3/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/KIBU3/lib/python3.9/site-packages/keras/src/engine/training.py:2296\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2292\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   2293\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2294\u001b[0m             ):\n\u001b[1;32m   2295\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2296\u001b[0m                 logs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_function_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2297\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2298\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2299\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2300\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2301\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2303\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2304\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/KIBU3/lib/python3.9/site-packages/keras/src/engine/training.py:4108\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[0;32m-> 4108\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   4110\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/KIBU3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/KIBU3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/KIBU3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/KIBU3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/KIBU3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/KIBU3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/KIBU3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/KIBU3/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/KIBU3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history= model.fit(traingen,batch_size=128,epochs=100,verbose=1,validation_data=valgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# モデルの訓練\n",
    "for epoch in range(3):  # エポック数を3に設定\n",
    "    for batch in dataset:\n",
    "        visual_embedding, text_embedding, decoder_input_ids = batch\n",
    "        model.train_on_batch([visual_embedding, text_embedding, decoder_input_ids], decoder_input_ids)\n",
    "\n",
    "print(\"Model training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/t32303m/anaconda3/envs/KIBU3/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('./0Data/model/gpu/model_t5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 入力例\n",
    "#text_input = \"I am a Ironman.\"\n",
    "text_input = tokenizer('What does she do?', return_tensors='tf', padding='max_length', max_length=30).input_ids\n",
    "text_embedding = t5.encoder(input_ids=text_input).last_hidden_state\n",
    "path = \"./0Data/MSCOCO/train2014/COCO_train2014_000000000110.jpg\"\n",
    "img = cv2.imread(path)\n",
    "img = cv2.resize(img, (224, 224))\n",
    "visual_input = np.array(img) / 255.0\n",
    "visual_input = np.expand_dims(visual_input, axis=0)\n",
    "\n",
    "# visual_input = tf.random.uniform((1, 224, 224, 3), minval=-1, maxval=1)\n",
    "\n",
    "# デコーダの入力用IDを作成\n",
    "decoder_input_ids = tokenizer('<pad>', return_tensors='tf', padding='max_length', max_length=30, truncation=True).input_ids\n",
    "\n",
    "# 予測\n",
    "output = model([visual_input, text_embedding,decoder_input_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan], shape=(512,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "outputs = model([visual_input, text_embedding,decoder_input_ids])\n",
    "print(outputs[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KIBU3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
